# NeuralRAG Environment Configuration
# Copy this file to .env and customize as needed

# =========================================
# LLM Configuration
# =========================================

# Main chat model (default: llama3)
RAG_LLM_MODEL=llama3

# Vision model for image analysis (default: llava)
RAG_VISION_MODEL=llava

# Embedding model for vector search
RAG_EMBED_MODEL=all-mpnet-base-v2

# =========================================
# Storage Paths
# =========================================

# Directory for uploaded documents
RAG_DATA_DIR=data

# ChromaDB storage directory
RAG_CHROMA_DIR=chroma_db

# =========================================
# Chunking Configuration
# =========================================

# Size of document chunks (in characters)
RAG_CHUNK_SIZE=1000

# Overlap between chunks
RAG_CHUNK_OVERLAP=100

# =========================================
# Ollama Configuration (for Docker)
# =========================================

# Ollama host (use 'ollama' for Docker, 'localhost' for local dev)
# OLLAMA_HOST=http://ollama:11434
